{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Jupyter Notebook combining all the steps\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "# 2. Explore Data\n",
    "print(\"\\nFirst few rows of training data:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Check distribution of labels\n",
    "plt.figure(figsize=(10, 5))\n",
    "train_data['label'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Distribution of Digits in Training Set')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 3. Preprocess Data\n",
    "print(\"\\nPreprocessing data...\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = train_data.iloc[:, 1:].values\n",
    "y = train_data.iloc[:, 0].values\n",
    "X_test = test_data.values\n",
    "\n",
    "# Normalize\n",
    "X = X.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# One-hot encode labels\n",
    "y = to_categorical(y, num_classes=10)\n",
    "\n",
    "# Split into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# 4. Visualize some samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    img = X_train[i].reshape(28, 28)\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(f\"Label: {np.argmax(y_train[i])}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Build Model\n",
    "print(\"\\nBuilding model...\")\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(28, 28, 1)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 6. Define Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/digit_recognizer.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=0.00001,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# 7. Train Model\n",
    "print(\"\\nTraining model...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 8. Plot Training History\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(history.history['loss'], label='Training Loss')\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Training History', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. Evaluate Model\n",
    "print(\"\\nEvaluating model...\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"Validation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_probs = model.predict(X_val, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# 10. Analyze Misclassifications\n",
    "misclassified_idx = np.where(y_true != y_pred)[0]\n",
    "\n",
    "if len(misclassified_idx) > 0:\n",
    "    print(f\"\\nTotal misclassifications: {len(misclassified_idx)}\")\n",
    "    print(f\"Misclassification rate: {len(misclassified_idx)/len(y_true)*100:.2f}%\")\n",
    "    \n",
    "    # Visualize some misclassifications\n",
    "    num_samples = min(5, len(misclassified_idx))\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, idx in enumerate(misclassified_idx[:num_samples]):\n",
    "        img = X_val[idx].reshape(28, 28)\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].set_title(f\"True: {y_true[idx]}, Pred: {y_pred[idx]}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Misclassified Samples', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nNo misclassifications found!\")\n",
    "\n",
    "# 11. Make Predictions on Test Set\n",
    "print(\"\\nMaking predictions on test set...\")\n",
    "\n",
    "test_predictions = model.predict(X_test, verbose=0)\n",
    "test_pred_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Visualize some test predictions\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_test[i].reshape(28, 28)\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(f\"Predicted: {test_pred_labels[i]}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Test Set Predictions', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 12. Create Submission File\n",
    "submission = pd.DataFrame({\n",
    "    'ImageId': range(1, len(test_pred_labels) + 1),\n",
    "    'Label': test_pred_labels\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"\\nSubmission file created: submission.csv\")\n",
    "print(f\"First few predictions:\")\n",
    "print(submission.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
